[I] Loading dataset Attack-Polblogs...
train_mask, test_mask, val_mask sizes : tensor(121) tensor(123) tensor(978)
[I] Finished loading.
[I] Data load time: 0.9950s
{'seeds': [1, 2, 3, 4], 'device': 0, 'max_epoch': 1500, 'warmup_steps': -1, 'num_heads': 4, 'num_out_heads': 1, 'num_layers': 2, 'num_dec_layers': 1, 'num_remasking': 3, 'num_hidden': 64, 'residual': False, 'in_drop': 0.2, 'attn_drop': 0.1, 'norm': None, 'lr': 0.0005, 'weight_decay': 0.0001, 'negative_slope': 0.2, 'activation': 'prelu', 'mask_rate': 0.5, 'remask_rate': 0.5, 'remask_method': 'random', 'mask_type': 'mask', 'mask_method': 'random', 'drop_edge_rate': 0.0, 'drop_edge_rate_f': 0.0, 'encoder': 'gat', 'decoder': 'gat', 'loss_fn': 'sce', 'alpha_l': 1, 'optimizer': 'adam', 'max_epoch_f': 500, 'lr_f': 0.025, 'weight_decay_f': 0.01, 'linear_prob': True, 'no_pretrain': False, 'load_model': False, 'checkpoint_path': None, 'use_cfg': True, 'logging': False, 'scheduler': True, 'batch_size': 256, 'batch_size_f': 128, 'sampling_method': 'saint', 'label_rate': 1.0, 'ego_graph_file_path': None, 'data_dir': 'data', 'lam': 0.1, 'full_graph_forward': False, 'delayed_ema_epoch': 0, 'replace_rate': 0.0, 'momentum': 1}
####### Run 0 for seed 1
=== Use sce_loss and alpha_l=1 ===
num_encoder_params: 99842, num_decoder_params: 99830, num_params_in_total: 242572
# IGNORE: --- TestAcc: 0.8548, early-stopping-TestAcc: 0.8548, Best ValAcc: 0.8699 in epoch 499 --- 
# IGNORE: --- TestAcc: 0.8589, early-stopping-TestAcc: 0.8609, Best ValAcc: 0.8780 in epoch 39 --- 
# IGNORE: --- TestAcc: 0.8630, early-stopping-TestAcc: 0.8630, Best ValAcc: 0.8862 in epoch 28 --- 
# IGNORE: --- TestAcc: 0.8620, early-stopping-TestAcc: 0.8742, Best ValAcc: 0.9024 in epoch 5 --- 
# IGNORE: --- TestAcc: 0.8569, early-stopping-TestAcc: 0.8620, Best ValAcc: 0.8699 in epoch 32 --- 
# IGNORE: --- TestAcc: 0.8487, early-stopping-TestAcc: 0.8497, Best ValAcc: 0.8618 in epoch 45 --- 
# IGNORE: --- TestAcc: 0.8497, early-stopping-TestAcc: 0.8487, Best ValAcc: 0.8618 in epoch 34 --- 
num parameters for finetuning: 130
--- TestAcc: 0.8497, early-stopping-TestAcc: 0.8497, Best ValAcc: 0.8618 in epoch 41 --- 
####### Run 1 for seed 2
=== Use sce_loss and alpha_l=1 ===
num_encoder_params: 99842, num_decoder_params: 99830, num_params_in_total: 242572
# IGNORE: --- TestAcc: 0.8252, early-stopping-TestAcc: 0.8783, Best ValAcc: 0.8699 in epoch 1 --- 
# IGNORE: --- TestAcc: 0.8548, early-stopping-TestAcc: 0.8671, Best ValAcc: 0.8862 in epoch 19 --- 
# IGNORE: --- TestAcc: 0.8579, early-stopping-TestAcc: 0.8640, Best ValAcc: 0.8862 in epoch 25 --- 
# IGNORE: --- TestAcc: 0.8650, early-stopping-TestAcc: 0.8650, Best ValAcc: 0.8943 in epoch 499 --- 
# IGNORE: --- TestAcc: 0.8681, early-stopping-TestAcc: 0.8681, Best ValAcc: 0.9024 in epoch 62 --- 
# IGNORE: --- TestAcc: 0.8691, early-stopping-TestAcc: 0.8691, Best ValAcc: 0.9024 in epoch 92 --- 
# IGNORE: --- TestAcc: 0.8630, early-stopping-TestAcc: 0.8650, Best ValAcc: 0.9024 in epoch 64 --- 
num parameters for finetuning: 130
--- TestAcc: 0.8630, early-stopping-TestAcc: 0.8650, Best ValAcc: 0.9024 in epoch 65 --- 
####### Run 2 for seed 3
=== Use sce_loss and alpha_l=1 ===
num_encoder_params: 99842, num_decoder_params: 99830, num_params_in_total: 242572
# IGNORE: --- TestAcc: 0.8671, early-stopping-TestAcc: 0.8661, Best ValAcc: 0.8943 in epoch 33 --- 
# IGNORE: --- TestAcc: 0.8609, early-stopping-TestAcc: 0.8640, Best ValAcc: 0.9024 in epoch 25 --- 
# IGNORE: --- TestAcc: 0.8630, early-stopping-TestAcc: 0.8722, Best ValAcc: 0.9106 in epoch 35 --- 
# IGNORE: --- TestAcc: 0.8630, early-stopping-TestAcc: 0.8671, Best ValAcc: 0.9106 in epoch 34 --- 
# IGNORE: --- TestAcc: 0.8620, early-stopping-TestAcc: 0.8650, Best ValAcc: 0.9024 in epoch 46 --- 
# IGNORE: --- TestAcc: 0.8650, early-stopping-TestAcc: 0.8620, Best ValAcc: 0.9106 in epoch 49 --- 
# IGNORE: --- TestAcc: 0.8620, early-stopping-TestAcc: 0.8650, Best ValAcc: 0.9106 in epoch 39 --- 
num parameters for finetuning: 130
--- TestAcc: 0.8630, early-stopping-TestAcc: 0.8650, Best ValAcc: 0.9106 in epoch 31 --- 
####### Run 3 for seed 4
=== Use sce_loss and alpha_l=1 ===
num_encoder_params: 99842, num_decoder_params: 99830, num_params_in_total: 242572
# IGNORE: --- TestAcc: 0.8517, early-stopping-TestAcc: 0.8630, Best ValAcc: 0.8862 in epoch 14 --- 
# IGNORE: --- TestAcc: 0.8599, early-stopping-TestAcc: 0.8599, Best ValAcc: 0.8862 in epoch 499 --- 
# IGNORE: --- TestAcc: 0.8630, early-stopping-TestAcc: 0.8599, Best ValAcc: 0.9024 in epoch 18 --- 
# IGNORE: --- TestAcc: 0.8609, early-stopping-TestAcc: 0.8609, Best ValAcc: 0.8862 in epoch 499 --- 
# IGNORE: --- TestAcc: 0.8599, early-stopping-TestAcc: 0.8599, Best ValAcc: 0.8862 in epoch 499 --- 
# IGNORE: --- TestAcc: 0.8579, early-stopping-TestAcc: 0.8620, Best ValAcc: 0.9024 in epoch 16 --- 
# IGNORE: --- TestAcc: 0.8569, early-stopping-TestAcc: 0.8620, Best ValAcc: 0.8943 in epoch 26 --- 
num parameters for finetuning: 130
--- TestAcc: 0.8569, early-stopping-TestAcc: 0.8569, Best ValAcc: 0.8618 in epoch 42 --- 
# final_acc: 0.8581±0.0055
# early-stopping_acc: 0.8592±0.0064
