[I] Loading dataset Attack-ogbn-arxiv...
train_mask, test_mask, val_mask sizes : tensor(90941) tensor(29799) tensor(48603)
[I] Finished loading.
[I] Data load time: 8.6089s
------ Use best configs ------
{'seeds': [1], 'device': -1, 'max_epoch': 60, 'warmup_steps': -1, 'num_heads': 4, 'num_out_heads': 1, 'num_layers': 3, 'num_hidden': 1024, 'residual': False, 'in_drop': 0.2, 'attn_drop': 0.1, 'norm': 'layernorm', 'lr': 0.001, 'weight_decay': 0.0, 'negative_slope': 0.2, 'activation': 'prelu', 'mask_rate': 0.5, 'drop_edge_rate': 0.5, 'replace_rate': 0.0, 'encoder': 'gat', 'decoder': 'gat', 'loss_fn': 'sce', 'alpha_l': 3, 'optimizer': 'adamw', 'max_epoch_f': 1000, 'lr_f': 0.01, 'weight_decay_f': 0.0005, 'linear_prob': True, 'load_model': False, 'save_model': False, 'use_cfg': True, 'logging': False, 'scheduler': True, 'concat_hidden': False, 'pooling': 'mean', 'deg4feat': False, 'batch_size': 512, 'batch_size_f': 256}
####### Run 1 for seed 1
# Epoch 0 | train_loss: 0.4286, Memory: 3067.37 MB
# Epoch 1 | train_loss: 0.4035, Memory: 3067.73 MB
# Epoch 2 | train_loss: 0.3980, Memory: 3068.21 MB
# Epoch 3 | train_loss: 0.3961, Memory: 3068.39 MB
# Epoch 4 | train_loss: 0.3926, Memory: 3069.72 MB
# Epoch 5 | train_loss: 0.3910, Memory: 3069.47 MB
# Epoch 6 | train_loss: 0.3897, Memory: 3069.50 MB
# Epoch 7 | train_loss: 0.3885, Memory: 3069.74 MB
# Epoch 8 | train_loss: 0.3872, Memory: 3069.74 MB
# Epoch 9 | train_loss: 0.3855, Memory: 3070.00 MB
# Epoch 10 | train_loss: 0.3846, Memory: 3070.84 MB
# Epoch 11 | train_loss: 0.3844, Memory: 3071.09 MB
# Epoch 12 | train_loss: 0.3831, Memory: 3071.09 MB
# Epoch 13 | train_loss: 0.3836, Memory: 3071.11 MB
# Epoch 14 | train_loss: 0.3812, Memory: 3070.85 MB
# Epoch 15 | train_loss: 0.3817, Memory: 3070.60 MB
# Epoch 16 | train_loss: 0.3810, Memory: 3070.87 MB
# Epoch 17 | train_loss: 0.3814, Memory: 3071.11 MB
# Epoch 18 | train_loss: 0.3792, Memory: 3071.35 MB
# Epoch 19 | train_loss: 0.3785, Memory: 3071.60 MB
# Epoch 20 | train_loss: 0.3780, Memory: 3071.60 MB
# Epoch 21 | train_loss: 0.3778, Memory: 3071.11 MB
# Epoch 22 | train_loss: 0.3765, Memory: 3071.12 MB
# Epoch 23 | train_loss: 0.3773, Memory: 3071.36 MB
# Epoch 24 | train_loss: 0.3769, Memory: 3071.62 MB
# Epoch 25 | train_loss: 0.3761, Memory: 3071.87 MB
# Epoch 26 | train_loss: 0.3758, Memory: 3071.61 MB
# Epoch 27 | train_loss: 0.3755, Memory: 3071.61 MB
# Epoch 28 | train_loss: 0.3742, Memory: 3071.86 MB
# Epoch 29 | train_loss: 0.3746, Memory: 3071.88 MB
# Epoch 30 | train_loss: 0.3740, Memory: 3071.89 MB
# Epoch 31 | train_loss: 0.3728, Memory: 3071.65 MB
# Epoch 32 | train_loss: 0.3730, Memory: 3071.88 MB
# Epoch 33 | train_loss: 0.3732, Memory: 3071.63 MB
# Epoch 34 | train_loss: 0.3724, Memory: 3071.88 MB
# Epoch 35 | train_loss: 0.3724, Memory: 3072.12 MB
# Epoch 36 | train_loss: 0.3716, Memory: 3072.12 MB
# Epoch 37 | train_loss: 0.3717, Memory: 3071.88 MB
# Epoch 38 | train_loss: 0.3705, Memory: 3071.38 MB
# Epoch 39 | train_loss: 0.3714, Memory: 3071.16 MB
# Epoch 40 | train_loss: 0.3712, Memory: 3071.43 MB
# Epoch 41 | train_loss: 0.3704, Memory: 3071.68 MB
# Epoch 42 | train_loss: 0.3693, Memory: 3071.93 MB
# Epoch 43 | train_loss: 0.3694, Memory: 3072.18 MB
# Epoch 44 | train_loss: 0.3699, Memory: 3072.18 MB
# Epoch 45 | train_loss: 0.3694, Memory: 3071.68 MB
# Epoch 46 | train_loss: 0.3692, Memory: 3071.93 MB
# Epoch 47 | train_loss: 0.3691, Memory: 3071.69 MB
# Epoch 48 | train_loss: 0.3684, Memory: 3071.93 MB
# Epoch 49 | train_loss: 0.3689, Memory: 3071.94 MB
# Epoch 50 | train_loss: 0.3686, Memory: 3072.18 MB
# Epoch 51 | train_loss: 0.3682, Memory: 3072.19 MB
# Epoch 52 | train_loss: 0.3684, Memory: 3072.19 MB
# Epoch 53 | train_loss: 0.3689, Memory: 3071.94 MB
# Epoch 54 | train_loss: 0.3683, Memory: 3071.69 MB
# Epoch 55 | train_loss: 0.3677, Memory: 3071.44 MB
# Epoch 56 | train_loss: 0.3683, Memory: 3071.44 MB
# Epoch 57 | train_loss: 0.3674, Memory: 3071.71 MB
# Epoch 58 | train_loss: 0.3676, Memory: 3071.94 MB
# Epoch 59 | train_loss: 0.3673, Memory: 3071.94 MB
num_train: 169343, num_val: 169343, num_test: 169343
######## Prepare All Embedding used...
######## Run seed 0 for LinearProbing...
training sample:90941
--- TestAcc: 0.6604, Best ValAcc: 0.6617 in epoch 124 --- 
# final_acc: 0.6604, std: 0.0000
# final_acc: 0.6604±0.0000
# early-stopping_acc: 0.6604±0.0000
