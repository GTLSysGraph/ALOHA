GraphMAE Unit Test
Adaptive attack scenario: poisoning | Adaptive attack model: svd_gcn | Budget: 357 | Unit Ptb: 0.0973
[I] Loading dataset Unit-Citeseer...
train_mask, test_mask, val_mask sizes : tensor(211) tensor(211) tensor(1688)
[I] Finished loading.
[I] Data load time: 3.0501s
Graph(num_nodes=2110, num_edges=10160,
      ndata_schemes={'feat': Scheme(shape=(3703,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
------ Use best configs ------
{'seeds': [1, 2], 'device': -1, 'max_epoch': 300, 'warmup_steps': -1, 'num_heads': 2, 'num_out_heads': 1, 'num_layers': 2, 'num_hidden': 64, 'residual': False, 'in_drop': 0.2, 'attn_drop': 0.1, 'norm': None, 'lr': 0.001, 'weight_decay': 2e-05, 'negative_slope': 0.2, 'activation': 'prelu', 'mask_rate': 0.5, 'drop_edge_rate': 0.0, 'replace_rate': 0.1, 'encoder': 'gat', 'decoder': 'gat', 'loss_fn': 'sce', 'alpha_l': 1, 'optimizer': 'adam', 'max_epoch_f': 300, 'lr_f': 0.01, 'weight_decay_f': 0.01, 'linear_prob': True, 'load_model': False, 'save_model': False, 'use_cfg': True, 'logging': False, 'scheduler': True, 'concat_hidden': False, 'pooling': 'mean', 'deg4feat': False, 'batch_size': 32, 'batch_size_f': 256}
####### Run 1 for seed 1
# IGNORE: --- TestAcc: 0.7370, early-stopping-TestAcc: 0.7370, Best ValAcc: 0.7109 in epoch 299 --- 
num parameters for finetuning: 390
--- TestAcc: 0.7382, early-stopping-TestAcc: 0.7352, Best ValAcc: 0.7204 in epoch 82 --- 
####### Run 2 for seed 2
# IGNORE: --- TestAcc: 0.7524, early-stopping-TestAcc: 0.7524, Best ValAcc: 0.7393 in epoch 299 --- 
num parameters for finetuning: 390
--- TestAcc: 0.7506, early-stopping-TestAcc: 0.7506, Best ValAcc: 0.7393 in epoch 299 --- 
# final_acc: 0.7444±0.0062
# early-stopping_acc: 0.7429±0.0077
